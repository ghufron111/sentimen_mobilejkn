{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e5e378f-1495-4354-a9d1-f1f820853f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters for SVM: {'svm__alpha': 0.0001, 'svm__max_iter': 1000}\n",
      "SVM Test Accuracy: 0.57055\n",
      "SVM Precision: 0.6465039239395692\n",
      "SVM Recall: 0.57055\n",
      "SVM F1-Score: 0.5823968843732784\n",
      "Random Forest Test Accuracy: 0.71545\n",
      "Random Forest Precision: 0.7230285722182033\n",
      "Random Forest Recall: 0.71545\n",
      "Random Forest F1-Score: 0.7131417241685111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kurotsuki\\PycharmProjects\\mobile_jkn_baru\\.venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [21:44:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test Accuracy: 0.71135\n",
      "XGBoost Precision: 0.7534009095092872\n",
      "XGBoost Recall: 0.71135\n",
      "XGBoost F1-Score: 0.7309879348846319\n",
      "\n",
      "Perbandingan Hasil Model:\n",
      "SVM Test Accuracy: 0.57055, Precision: 0.6465039239395692, Recall: 0.57055, F1-Score: 0.5823968843732784\n",
      "Random Forest Test Accuracy: 0.71545, Precision: 0.7230285722182033, Recall: 0.71545, F1-Score: 0.7131417241685111\n",
      "XGBoost Test Accuracy: 0.71135, Precision: 0.7534009095092872, Recall: 0.71135, F1-Score: 0.7309879348846319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import nltk\n",
    "\n",
    "# Pastikan untuk mengunduh resource NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Fungsi untuk membersihkan teks\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('dataset/mobile_jkn.csv')  # Load your CSV file\n",
    "\n",
    "# Preprocess the text\n",
    "data['content'] = data['content'].apply(preprocess_text)\n",
    "\n",
    "# Assume 'content' contains review text and 'score' contains sentiment labels\n",
    "X = data['content']  # Feature: text reviews\n",
    "y = data['score']    # Label: sentiment\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "max_words = 5000  # Maximum number of words to consider\n",
    "max_len = 200     # Maximum length of input sequences\n",
    "embedding_dim = 128  # Embedding size for each token\n",
    "\n",
    "# Tokenization of the text data\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the text data to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure uniform input shape\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "lb = LabelBinarizer()\n",
    "y_train_onehot = lb.fit_transform(y_train)\n",
    "y_test_onehot = lb.transform(y_test)\n",
    "\n",
    "# -------------------- Penyeimbangan Data Menggunakan SMOTE -------------------- #\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_padded_resampled, y_train_onehot_resampled = smote.fit_resample(X_train_padded, y_train_onehot)\n",
    "\n",
    "# Flatten y_train_onehot_resampled and y_test_onehot for compatibility\n",
    "y_train_flat = y_train_onehot_resampled.argmax(axis=1)\n",
    "y_test_flat = y_test_onehot.argmax(axis=1)\n",
    "\n",
    "# -------------------- Mencoba Model SVM dengan Tuning Hyperparameter -------------------- #\n",
    "# Grid Search untuk hyperparameter SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SGDClassifier(loss='hinge', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'svm__alpha': [1e-3, 1e-4, 1e-5],  # Regularization strength\n",
    "    'svm__max_iter': [1000, 2000],  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_pipeline, param_grid, cv=5, scoring='f1_weighted', verbose=1)\n",
    "grid_search_svm.fit(X_train_padded_resampled, y_train_flat)\n",
    "\n",
    "# Hasil terbaik dari Grid Search\n",
    "best_svm_model = grid_search_svm.best_estimator_\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_svm_batch = best_svm_model.predict(X_test_padded)\n",
    "\n",
    "# SVM Accuracy\n",
    "svm_batch_accuracy = accuracy_score(y_test_flat, y_pred_svm_batch)\n",
    "print(f\"SVM Test Accuracy: {svm_batch_accuracy}\")\n",
    "\n",
    "# SVM Precision, Recall, F1-Score\n",
    "svm_batch_precision = precision_score(y_test_flat, y_pred_svm_batch, average='weighted')\n",
    "svm_batch_recall = recall_score(y_test_flat, y_pred_svm_batch, average='weighted')\n",
    "svm_batch_f1 = f1_score(y_test_flat, y_pred_svm_batch, average='weighted')\n",
    "\n",
    "print(f\"SVM Precision: {svm_batch_precision}\")\n",
    "print(f\"SVM Recall: {svm_batch_recall}\")\n",
    "print(f\"SVM F1-Score: {svm_batch_f1}\")\n",
    "\n",
    "# -------------------- Mencoba Model Random Forest -------------------- #\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_padded_resampled, y_train_flat)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = rf_model.predict(X_test_padded)\n",
    "\n",
    "# Random Forest Accuracy\n",
    "rf_accuracy = accuracy_score(y_test_flat, y_pred_rf)\n",
    "print(f\"Random Forest Test Accuracy: {rf_accuracy}\")\n",
    "\n",
    "# Random Forest Precision, Recall, F1-Score\n",
    "rf_precision = precision_score(y_test_flat, y_pred_rf, average='weighted')\n",
    "rf_recall = recall_score(y_test_flat, y_pred_rf, average='weighted')\n",
    "rf_f1 = f1_score(y_test_flat, y_pred_rf, average='weighted')\n",
    "\n",
    "print(f\"Random Forest Precision: {rf_precision}\")\n",
    "print(f\"Random Forest Recall: {rf_recall}\")\n",
    "print(f\"Random Forest F1-Score: {rf_f1}\")\n",
    "\n",
    "# -------------------- Mencoba Model XGBoost -------------------- #\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train_padded_resampled, y_train_flat)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_xgb = xgb_model.predict(X_test_padded)\n",
    "\n",
    "# XGBoost Accuracy\n",
    "xgb_accuracy = accuracy_score(y_test_flat, y_pred_xgb)\n",
    "print(f\"XGBoost Test Accuracy: {xgb_accuracy}\")\n",
    "\n",
    "# XGBoost Precision, Recall, F1-Score\n",
    "xgb_precision = precision_score(y_test_flat, y_pred_xgb, average='weighted')\n",
    "xgb_recall = recall_score(y_test_flat, y_pred_xgb, average='weighted')\n",
    "xgb_f1 = f1_score(y_test_flat, y_pred_xgb, average='weighted')\n",
    "\n",
    "print(f\"XGBoost Precision: {xgb_precision}\")\n",
    "print(f\"XGBoost Recall: {xgb_recall}\")\n",
    "print(f\"XGBoost F1-Score: {xgb_f1}\")\n",
    "\n",
    "# -------------------- Perbandingan Hasil Model -------------------- #\n",
    "print(\"\\nPerbandingan Hasil Model:\")\n",
    "print(f\"SVM Test Accuracy: {svm_batch_accuracy}, Precision: {svm_batch_precision}, Recall: {svm_batch_recall}, F1-Score: {svm_batch_f1}\")\n",
    "print(f\"Random Forest Test Accuracy: {rf_accuracy}, Precision: {rf_precision}, Recall: {rf_recall}, F1-Score: {rf_f1}\")\n",
    "print(f\"XGBoost Test Accuracy: {xgb_accuracy}, Precision: {xgb_precision}, Recall: {xgb_recall}, F1-Score: {xgb_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c717d5-7556-43de-a622-aef4cb82e6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
