{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09909e5b-c6df-4c9a-adda-71cfadf1774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4a7b8e-f14d-4a0e-8109-20f868d0745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set memory growth for GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500a411a-9cb0-4f9d-b0fe-b467e0bae73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('dataset/mobile_jkn.csv')\n",
    "\n",
    "# Preprocessing function to clean text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\d', ' ', text)  # Remove digits\n",
    "    text = text.lower()              # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text) # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the 'Review' column\n",
    "data['content'] = data['content'].apply(preprocess_text)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data['content']\n",
    "y = data['score']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9326d3cf-4730-4fb7-a3a6-877eed60258a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3863/3863 [==============================] - 124s 31ms/step - loss: 1.2798 - accuracy: 0.4285 - val_loss: 0.7950 - val_accuracy: 0.7896\n",
      "Epoch 2/100\n",
      "3863/3863 [==============================] - 124s 32ms/step - loss: 1.1748 - accuracy: 0.4786 - val_loss: 0.7435 - val_accuracy: 0.8131\n",
      "Epoch 3/100\n",
      "3863/3863 [==============================] - 123s 32ms/step - loss: 1.1400 - accuracy: 0.4928 - val_loss: 0.7449 - val_accuracy: 0.8037\n",
      "Epoch 4/100\n",
      "3863/3863 [==============================] - 124s 32ms/step - loss: 1.1178 - accuracy: 0.5030 - val_loss: 0.7345 - val_accuracy: 0.7416\n",
      "Epoch 5/100\n",
      "3863/3863 [==============================] - 125s 32ms/step - loss: 1.0998 - accuracy: 0.5112 - val_loss: 0.7210 - val_accuracy: 0.7965\n",
      "Epoch 6/100\n",
      "3863/3863 [==============================] - 123s 32ms/step - loss: 1.0831 - accuracy: 0.5195 - val_loss: 0.7381 - val_accuracy: 0.8097\n",
      "Epoch 7/100\n",
      "3863/3863 [==============================] - 123s 32ms/step - loss: 1.0687 - accuracy: 0.5276 - val_loss: 0.7381 - val_accuracy: 0.7934\n",
      "Epoch 8/100\n",
      "3863/3863 [==============================] - 123s 32ms/step - loss: 1.0556 - accuracy: 0.5355 - val_loss: 0.7532 - val_accuracy: 0.8120\n",
      "Epoch 9/100\n",
      "3863/3863 [==============================] - 123s 32ms/step - loss: 1.0418 - accuracy: 0.5430 - val_loss: 0.7753 - val_accuracy: 0.7965\n",
      "Epoch 10/100\n",
      "3863/3863 [==============================] - 124s 32ms/step - loss: 1.0307 - accuracy: 0.5490 - val_loss: 0.7939 - val_accuracy: 0.7215\n",
      "Epoch 11/100\n",
      "3863/3863 [==============================] - 124s 32ms/step - loss: 1.0198 - accuracy: 0.5550 - val_loss: 0.7743 - val_accuracy: 0.8130\n",
      "Epoch 12/100\n",
      "3863/3863 [==============================] - 124s 32ms/step - loss: 1.0092 - accuracy: 0.5615 - val_loss: 0.8303 - val_accuracy: 0.8073\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.7435 - accuracy: 0.8131\n",
      "LSTM Test Loss: 0.7435, Test Accuracy: 0.8131\n"
     ]
    }
   ],
   "source": [
    "# --- LSTM Model ---\n",
    "\n",
    "# Tokenization and Padding for LSTM\n",
    "max_words = 10000  # Vocabulary size\n",
    "max_len = 150      # Max length for padding\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Convert ratings to one-hot encoding\n",
    "lb = LabelBinarizer()\n",
    "y_train_onehot = lb.fit_transform(y_train)\n",
    "y_test_onehot = lb.transform(y_test)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_padded, y_train_onehot)\n",
    "\n",
    "# Build and compile LSTM model\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_words, 128, input_length=max_len),\n",
    "    tf.keras.layers.SpatialDropout1D(0.3),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),  # Increase LSTM units\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),  # Increase units\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(y_train_onehot.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "lstm_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)  # Monitor val_accuracy\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=64,\n",
    "               validation_data=(X_test_padded, y_test_onehot), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate LSTM model\n",
    "lstm_test_loss, lstm_test_accuracy = lstm_model.evaluate(X_test_padded, y_test_onehot)\n",
    "\n",
    "print(f\"LSTM Test Loss: {lstm_test_loss:.4f}, Test Accuracy: {lstm_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e48e634-f3d6-47b5-bc4a-fe0866c8997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 trained.\n",
      "Batch 2 trained.\n",
      "Batch 3 trained.\n",
      "Batch 4 trained.\n",
      "Batch 5 trained.\n",
      "Batch 6 trained.\n",
      "Batch 7 trained.\n",
      "Batch 8 trained.\n",
      "Batch 9 trained.\n",
      "Batch 10 trained.\n",
      "Batch 11 trained.\n",
      "Batch 12 trained.\n",
      "Batch 13 trained.\n",
      "Batch 14 trained.\n",
      "Batch 15 trained.\n",
      "Batch 16 trained.\n",
      "Batch 17 trained.\n",
      "Batch 18 trained.\n",
      "Batch 19 trained.\n",
      "Batch 20 trained.\n",
      "Batch 21 trained.\n",
      "Batch 22 trained.\n",
      "Batch 23 trained.\n",
      "Batch 24 trained.\n",
      "Batch 25 trained.\n",
      "SVM Test Accuracy with mini-batch training: 0.6248\n"
     ]
    }
   ],
   "source": [
    "# Reduce TF-IDF features to 1000\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Handle class imbalance using SMOTE for SVM\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_svm, y_train_resampled_svm = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Convert resampled sparse matrix to dense (array)\n",
    "X_train_resampled_svm = X_train_resampled_svm.toarray()\n",
    "y_train_resampled_svm = np.array(y_train_resampled_svm)\n",
    "\n",
    "# Define a mini-batch size\n",
    "batch_size = 10000\n",
    "\n",
    "# Shuffle the resampled data\n",
    "X_train_resampled_svm, y_train_resampled_svm = shuffle(X_train_resampled_svm, y_train_resampled_svm, random_state=42)\n",
    "\n",
    "# Initialize SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Train SVM using mini-batch approach\n",
    "for i in range(0, X_train_resampled_svm.shape[0], batch_size):\n",
    "    X_batch = X_train_resampled_svm[i:i+batch_size]\n",
    "    y_batch = y_train_resampled_svm[i:i+batch_size]\n",
    "    svm_model.fit(X_batch, y_batch)  # Train on the current batch\n",
    "    print(f\"Batch {i // batch_size + 1} trained.\")\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf.toarray())\n",
    "svm_test_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"SVM Test Accuracy with mini-batch training: {svm_test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6067613-d1bc-4b0a-a1ef-c5775704013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Naive Bayes Model ---\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate Naive Bayes model\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "nb_test_accuracy = accuracy_score(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6abc3452-f4f4-460b-a544-69b2f3148ed5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Print accuracies\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_test_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msvm_test_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive Bayes Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnb_test_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lstm_test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# Print accuracies\n",
    "print(f\"LSTM Test Accuracy: {lstm_test_accuracy}\")\n",
    "print(f\"SVM Test Accuracy: {svm_test_accuracy}\")\n",
    "print(f\"Naive Bayes Test Accuracy: {nb_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571efca0-22e2-4fd4-b207-87949ef1f7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
