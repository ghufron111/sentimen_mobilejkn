{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1821b8c-c599-402f-94c4-a98136e5d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ac447bd-bf7e-40f1-a165-7ea21b39965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function for preprocessing text\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('dataset/mobile_jkn.csv')  # Load your CSV file\n",
    "\n",
    "# Preprocess text data\n",
    "data['content'] = data['content'].apply(preprocess_text)\n",
    "\n",
    "# Remove empty content\n",
    "data = data[data['content'].str.strip() != '']  # Remove empty reviews\n",
    "\n",
    "# Features and labels\n",
    "X = data['content']\n",
    "y = data['score']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "847e6752-8777-4328-8d4e-a6a9bb4b8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for text data\n",
    "max_words = 10000\n",
    "max_len = 150\n",
    "embedding_dim = 128\n",
    "\n",
    "# Tokenization and Padding\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Label Binarization\n",
    "lb = LabelBinarizer()\n",
    "y_train_onehot = lb.fit_transform(y_train)\n",
    "y_test_onehot = lb.transform(y_test)\n",
    "\n",
    "# Resampling using SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)  # Generates a 50-50 balance\n",
    "X_train_resampled, y_train_onehot_resampled = smote.fit_resample(X_train_padded, y_train_onehot)\n",
    "\n",
    "# Flattening for compatibility with models\n",
    "y_train_flat = y_train_onehot_resampled.argmax(axis=1)\n",
    "y_test_flat = y_test_onehot.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20deb890-4553-4c76-a0c3-b286acf71ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3796/3796 [==============================] - 99s 25ms/step - loss: 1.3286 - accuracy: 0.4168 - val_loss: 0.8403 - val_accuracy: 0.7725\n",
      "Epoch 2/100\n",
      "3796/3796 [==============================] - 98s 26ms/step - loss: 1.2050 - accuracy: 0.4635 - val_loss: 0.8114 - val_accuracy: 0.7673\n",
      "Epoch 3/100\n",
      "3796/3796 [==============================] - 98s 26ms/step - loss: 1.1829 - accuracy: 0.4738 - val_loss: 0.8323 - val_accuracy: 0.7197\n",
      "Epoch 4/100\n",
      "3796/3796 [==============================] - 97s 26ms/step - loss: 1.1669 - accuracy: 0.4803 - val_loss: 0.7956 - val_accuracy: 0.7883\n",
      "Epoch 5/100\n",
      "3796/3796 [==============================] - 97s 26ms/step - loss: 1.1570 - accuracy: 0.4862 - val_loss: 0.8580 - val_accuracy: 0.7325\n",
      "Epoch 6/100\n",
      "3796/3796 [==============================] - 97s 26ms/step - loss: 1.1509 - accuracy: 0.4904 - val_loss: 0.7578 - val_accuracy: 0.7962\n",
      "Epoch 7/100\n",
      "3796/3796 [==============================] - 99s 26ms/step - loss: 1.1400 - accuracy: 0.4953 - val_loss: 0.8322 - val_accuracy: 0.7732\n",
      "Epoch 8/100\n",
      "3796/3796 [==============================] - 99s 26ms/step - loss: 1.1338 - accuracy: 0.4982 - val_loss: 0.8687 - val_accuracy: 0.6966\n",
      "Epoch 9/100\n",
      "3796/3796 [==============================] - 99s 26ms/step - loss: 1.1273 - accuracy: 0.5019 - val_loss: 0.7684 - val_accuracy: 0.7960\n",
      "Epoch 10/100\n",
      "3796/3796 [==============================] - 99s 26ms/step - loss: 1.1221 - accuracy: 0.5062 - val_loss: 0.8043 - val_accuracy: 0.7811\n",
      "Epoch 11/100\n",
      "3796/3796 [==============================] - 94s 25ms/step - loss: 1.1171 - accuracy: 0.5077 - val_loss: 0.8245 - val_accuracy: 0.7174\n",
      "Epoch 12/100\n",
      "3796/3796 [==============================] - 96s 25ms/step - loss: 1.1124 - accuracy: 0.5105 - val_loss: 0.7474 - val_accuracy: 0.8004\n",
      "Epoch 13/100\n",
      "3796/3796 [==============================] - 96s 25ms/step - loss: 1.1072 - accuracy: 0.5134 - val_loss: 0.8639 - val_accuracy: 0.6938\n",
      "Epoch 14/100\n",
      "3796/3796 [==============================] - 98s 26ms/step - loss: 1.1032 - accuracy: 0.5146 - val_loss: 0.8106 - val_accuracy: 0.7814\n",
      "Epoch 15/100\n",
      "3796/3796 [==============================] - 95s 25ms/step - loss: 1.1002 - accuracy: 0.5179 - val_loss: 0.8054 - val_accuracy: 0.7761\n",
      "Epoch 16/100\n",
      "3796/3796 [==============================] - 100s 26ms/step - loss: 1.0957 - accuracy: 0.5200 - val_loss: 0.8009 - val_accuracy: 0.7730\n",
      "Epoch 17/100\n",
      "3796/3796 [==============================] - 15746s 4s/step - loss: 1.0931 - accuracy: 0.5206 - val_loss: 0.8351 - val_accuracy: 0.7471\n",
      "Epoch 18/100\n",
      "3796/3796 [==============================] - 95s 25ms/step - loss: 1.0895 - accuracy: 0.5234 - val_loss: 0.8249 - val_accuracy: 0.7704\n",
      "Epoch 19/100\n",
      "3796/3796 [==============================] - 116s 31ms/step - loss: 1.0847 - accuracy: 0.5266 - val_loss: 0.8275 - val_accuracy: 0.7306\n",
      "Epoch 20/100\n",
      "3796/3796 [==============================] - 108s 29ms/step - loss: 1.0823 - accuracy: 0.5277 - val_loss: 0.8094 - val_accuracy: 0.7941\n",
      "Epoch 21/100\n",
      "3796/3796 [==============================] - 104s 27ms/step - loss: 1.0778 - accuracy: 0.5296 - val_loss: 0.8019 - val_accuracy: 0.7919\n",
      "Epoch 22/100\n",
      "3796/3796 [==============================] - 103s 27ms/step - loss: 1.0762 - accuracy: 0.5319 - val_loss: 0.8513 - val_accuracy: 0.7746\n",
      "618/618 [==============================] - 8s 13ms/step - loss: 0.7474 - accuracy: 0.8004\n",
      "618/618 [==============================] - 8s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# --- Define and Train the LSTM Model ---\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_words, embedding_dim, input_length=max_len),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.01))),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(y_train_onehot.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "lstm_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model.fit(X_train_resampled, y_train_onehot_resampled, epochs=100, batch_size=64,\n",
    "               validation_data=(X_test_padded, y_test_onehot), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "lstm_test_loss, lstm_test_accuracy = lstm_model.evaluate(X_test_padded, y_test_onehot)\n",
    "\n",
    "# Predict with the LSTM model\n",
    "y_pred_lstm = lstm_model.predict(X_test_padded).argmax(axis=1)\n",
    "\n",
    "# LSTM metrics\n",
    "lstm_precision = precision_score(y_test_flat, y_pred_lstm, average='weighted')\n",
    "lstm_recall = recall_score(y_test_flat, y_pred_lstm, average='weighted')\n",
    "lstm_f1 = f1_score(y_test_flat, y_pred_lstm, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b01febf2-8d23-4e8a-bbb7-3d103b9d48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Random Forest Model ---\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_resampled, y_train_flat)\n",
    "\n",
    "# Predict with Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test_padded)\n",
    "\n",
    "# Random Forest metrics\n",
    "rf_accuracy = accuracy_score(y_test_flat, y_pred_rf)\n",
    "rf_precision = precision_score(y_test_flat, y_pred_rf, average='weighted')\n",
    "rf_recall = recall_score(y_test_flat, y_pred_rf, average='weighted')\n",
    "rf_f1 = f1_score(y_test_flat, y_pred_rf, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d48fd1af-a409-4cef-aa59-b0f43c7b094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XGBoost Model ---\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train_resampled, y_train_flat)\n",
    "\n",
    "# Predict with XGBoost\n",
    "y_pred_xgb = xgb_model.predict(X_test_padded)\n",
    "\n",
    "# XGBoost metrics\n",
    "xgb_accuracy = accuracy_score(y_test_flat, y_pred_xgb)\n",
    "xgb_precision = precision_score(y_test_flat, y_pred_xgb, average='weighted')\n",
    "xgb_recall = recall_score(y_test_flat, y_pred_xgb, average='weighted')\n",
    "xgb_f1 = f1_score(y_test_flat, y_pred_xgb, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c2cdec4-74b0-4493-bc2c-8d6f4ed3cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6095078979343864\n",
      "Precision: 0.6506680076502916\n",
      "Recall: 0.6095078979343864\n",
      "F1 Score: 0.5696082474581085\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes model\n",
    "nb_model = MultinomialNB(alpha=0.001)  # Adjust alpha for smoothing\n",
    "nb_model.fit(X_train_resampled, y_train_flat)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb_model.predict(X_test_padded)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_flat, y_pred)\n",
    "precision = precision_score(y_test_flat, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_flat, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_flat, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa63f5a2-b2c8-4bed-b482-f8cb36cd4164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Model Results With SMOTE:\n",
      "           Model  Accuracy  Precision    Recall  F1-Score\n",
      "0           LSTM  0.800425   0.774875  0.800425  0.784947\n",
      "1  Random Forest  0.701549   0.717198  0.701549  0.702007\n",
      "2        XGBoost  0.705954   0.746207  0.705954  0.724851\n",
      "3    Naive Bayes  0.609508   0.650668  0.609508  0.569608\n"
     ]
    }
   ],
   "source": [
    "# --- Model Results ---\n",
    "results = {\n",
    "    \"Model\": [\"LSTM\", \"Random Forest\", \"XGBoost\", \"Naive Bayes\"],\n",
    "    \"Accuracy\": [lstm_test_accuracy, rf_accuracy, xgb_accuracy, accuracy],\n",
    "    \"Precision\": [lstm_precision, rf_precision, xgb_precision, precision],\n",
    "    \"Recall\": [lstm_recall, rf_recall, xgb_recall, recall],\n",
    "    \"F1-Score\": [lstm_f1, rf_f1, xgb_f1, f1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "print(\"\\nComparison of Model Results With SMOTE:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca712f2-df85-4edc-a879-f38e0065110b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
