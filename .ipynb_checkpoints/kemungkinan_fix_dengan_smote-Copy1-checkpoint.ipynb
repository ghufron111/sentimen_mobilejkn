{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1821b8c-c599-402f-94c4-a98136e5d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ac447bd-bf7e-40f1-a165-7ea21b39965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function for preprocessing text\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('dataset/mobile_jkn.csv')  # Load your CSV file\n",
    "\n",
    "# Preprocess text data\n",
    "data['content'] = data['content'].apply(preprocess_text)\n",
    "\n",
    "# Remove empty content\n",
    "data = data[data['content'].str.strip() != '']  # Remove empty reviews\n",
    "\n",
    "# Features and labels\n",
    "X = data['content']\n",
    "y = data['score']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "847e6752-8777-4328-8d4e-a6a9bb4b8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for text data\n",
    "max_words = 10000\n",
    "max_len = 150\n",
    "embedding_dim = 128\n",
    "\n",
    "# Tokenization and Padding\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Label Binarization\n",
    "lb = LabelBinarizer()\n",
    "y_train_onehot = lb.fit_transform(y_train)\n",
    "y_test_onehot = lb.transform(y_test)\n",
    "\n",
    "# Resampling using SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)  # Generates a 50-50 balance\n",
    "X_train_resampled, y_train_onehot_resampled = smote.fit_resample(X_train_padded, y_train_onehot)\n",
    "\n",
    "# Flattening for compatibility with models\n",
    "y_train_flat = y_train_onehot_resampled.argmax(axis=1)\n",
    "y_test_flat = y_test_onehot.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20deb890-4553-4c76-a0c3-b286acf71ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3796/3796 [==============================] - 97s 25ms/step - loss: 1.3339 - accuracy: 0.4174 - val_loss: 0.8698 - val_accuracy: 0.7532\n",
      "Epoch 2/100\n",
      "3796/3796 [==============================] - 91s 24ms/step - loss: 1.2075 - accuracy: 0.4624 - val_loss: 0.8142 - val_accuracy: 0.7087\n",
      "Epoch 3/100\n",
      "3796/3796 [==============================] - 93s 25ms/step - loss: 1.1837 - accuracy: 0.4749 - val_loss: 0.8017 - val_accuracy: 0.7734\n",
      "Epoch 4/100\n",
      "3796/3796 [==============================] - 96s 25ms/step - loss: 1.1692 - accuracy: 0.4811 - val_loss: 0.7860 - val_accuracy: 0.7722\n",
      "Epoch 5/100\n",
      "3796/3796 [==============================] - 104s 27ms/step - loss: 1.1570 - accuracy: 0.4883 - val_loss: 0.7687 - val_accuracy: 0.7978\n",
      "Epoch 6/100\n",
      "3796/3796 [==============================] - 100s 26ms/step - loss: 1.1495 - accuracy: 0.4922 - val_loss: 0.7316 - val_accuracy: 0.7994\n",
      "Epoch 7/100\n",
      "3796/3796 [==============================] - 103s 27ms/step - loss: 1.1408 - accuracy: 0.4971 - val_loss: 0.8058 - val_accuracy: 0.7190\n",
      "Epoch 8/100\n",
      "3796/3796 [==============================] - 97s 26ms/step - loss: 1.1341 - accuracy: 0.5003 - val_loss: 0.8184 - val_accuracy: 0.7669\n",
      "Epoch 9/100\n",
      "3796/3796 [==============================] - 95s 25ms/step - loss: 1.1266 - accuracy: 0.5050 - val_loss: 0.7926 - val_accuracy: 0.7907\n",
      "Epoch 10/100\n",
      "3796/3796 [==============================] - 99s 26ms/step - loss: 1.1208 - accuracy: 0.5075 - val_loss: 0.7612 - val_accuracy: 0.7741\n",
      "Epoch 11/100\n",
      "3796/3796 [==============================] - 97s 26ms/step - loss: 1.1144 - accuracy: 0.5117 - val_loss: 0.8574 - val_accuracy: 0.7644\n",
      "Epoch 12/100\n",
      "3796/3796 [==============================] - 98s 26ms/step - loss: 1.1088 - accuracy: 0.5141 - val_loss: 0.7905 - val_accuracy: 0.7924\n",
      "Epoch 13/100\n",
      "3796/3796 [==============================] - 96s 25ms/step - loss: 1.1021 - accuracy: 0.5185 - val_loss: 0.8319 - val_accuracy: 0.7694\n",
      "Epoch 14/100\n",
      "3796/3796 [==============================] - 101s 27ms/step - loss: 1.0971 - accuracy: 0.5200 - val_loss: 0.7700 - val_accuracy: 0.8018\n",
      "Epoch 15/100\n",
      "3796/3796 [==============================] - 95s 25ms/step - loss: 1.0950 - accuracy: 0.5228 - val_loss: 0.8273 - val_accuracy: 0.7816\n",
      "Epoch 16/100\n",
      "3796/3796 [==============================] - 96s 25ms/step - loss: 1.0860 - accuracy: 0.5266 - val_loss: 0.8922 - val_accuracy: 0.7025\n",
      "Epoch 17/100\n",
      "3796/3796 [==============================] - 98s 26ms/step - loss: 1.0825 - accuracy: 0.5286 - val_loss: 0.8192 - val_accuracy: 0.7943\n",
      "Epoch 18/100\n",
      "3796/3796 [==============================] - 99s 26ms/step - loss: 1.0769 - accuracy: 0.5312 - val_loss: 0.8700 - val_accuracy: 0.7437\n",
      "Epoch 19/100\n",
      "3796/3796 [==============================] - 99s 26ms/step - loss: 1.0736 - accuracy: 0.5342 - val_loss: 0.8235 - val_accuracy: 0.7878\n",
      "Epoch 20/100\n",
      "3796/3796 [==============================] - 103s 27ms/step - loss: 1.0678 - accuracy: 0.5363 - val_loss: 0.8737 - val_accuracy: 0.7682\n",
      "Epoch 21/100\n",
      "3796/3796 [==============================] - 102s 27ms/step - loss: 1.0632 - accuracy: 0.5386 - val_loss: 0.8882 - val_accuracy: 0.7503\n",
      "Epoch 22/100\n",
      "3796/3796 [==============================] - 100s 26ms/step - loss: 1.0596 - accuracy: 0.5406 - val_loss: 0.8498 - val_accuracy: 0.7775\n",
      "Epoch 23/100\n",
      "3796/3796 [==============================] - 100s 26ms/step - loss: 1.0562 - accuracy: 0.5428 - val_loss: 0.9085 - val_accuracy: 0.7381\n",
      "Epoch 24/100\n",
      "3796/3796 [==============================] - 112s 30ms/step - loss: 1.0530 - accuracy: 0.5434 - val_loss: 0.8829 - val_accuracy: 0.7779\n",
      "618/618 [==============================] - 9s 14ms/step - loss: 0.7700 - accuracy: 0.8018\n",
      "618/618 [==============================] - 9s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# --- Define and Train the LSTM Model ---\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_words, embedding_dim, input_length=max_len),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.01))),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(y_train_onehot.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "lstm_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model.fit(X_train_resampled, y_train_onehot_resampled, epochs=100, batch_size=64,\n",
    "               validation_data=(X_test_padded, y_test_onehot), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "lstm_test_loss, lstm_test_accuracy = lstm_model.evaluate(X_test_padded, y_test_onehot)\n",
    "\n",
    "# Predict with the LSTM model\n",
    "y_pred_lstm = lstm_model.predict(X_test_padded).argmax(axis=1)\n",
    "\n",
    "# LSTM metrics\n",
    "lstm_precision = precision_score(y_test_flat, y_pred_lstm, average='weighted')\n",
    "lstm_recall = recall_score(y_test_flat, y_pred_lstm, average='weighted')\n",
    "lstm_f1 = f1_score(y_test_flat, y_pred_lstm, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b01febf2-8d23-4e8a-bbb7-3d103b9d48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Random Forest Model ---\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_resampled, y_train_flat)\n",
    "\n",
    "# Predict with Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test_padded)\n",
    "\n",
    "# Random Forest metrics\n",
    "rf_accuracy = accuracy_score(y_test_flat, y_pred_rf)\n",
    "rf_precision = precision_score(y_test_flat, y_pred_rf, average='weighted')\n",
    "rf_recall = recall_score(y_test_flat, y_pred_rf, average='weighted')\n",
    "rf_f1 = f1_score(y_test_flat, y_pred_rf, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d48fd1af-a409-4cef-aa59-b0f43c7b094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XGBoost Model ---\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train_resampled, y_train_flat)\n",
    "\n",
    "# Predict with XGBoost\n",
    "y_pred_xgb = xgb_model.predict(X_test_padded)\n",
    "\n",
    "# XGBoost metrics\n",
    "xgb_accuracy = accuracy_score(y_test_flat, y_pred_xgb)\n",
    "xgb_precision = precision_score(y_test_flat, y_pred_xgb, average='weighted')\n",
    "xgb_recall = recall_score(y_test_flat, y_pred_xgb, average='weighted')\n",
    "xgb_f1 = f1_score(y_test_flat, y_pred_xgb, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c2cdec4-74b0-4493-bc2c-8d6f4ed3cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6095078979343864\n",
      "Precision: 0.6506680076502916\n",
      "Recall: 0.6095078979343864\n",
      "F1 Score: 0.5696082474581085\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes model\n",
    "nb_model = MultinomialNB(alpha=0.001)  # Adjust alpha for smoothing\n",
    "nb_model.fit(X_train_resampled, y_train_flat)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb_model.predict(X_test_padded)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_flat, y_pred)\n",
    "precision = precision_score(y_test_flat, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_flat, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_flat, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa63f5a2-b2c8-4bed-b482-f8cb36cd4164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Model Results With SMOTE:\n",
      "           Model  Accuracy  Precision    Recall  F1-Score\n",
      "0           LSTM  0.801792   0.772197  0.801792  0.783995\n",
      "1  Random Forest  0.701549   0.717198  0.701549  0.702007\n",
      "2        XGBoost  0.705954   0.746207  0.705954  0.724851\n",
      "3    Naive Bayes  0.609508   0.650668  0.609508  0.569608\n"
     ]
    }
   ],
   "source": [
    "# --- Model Results ---\n",
    "results = {\n",
    "    \"Model\": [\"LSTM\", \"Random Forest\", \"XGBoost\", \"Naive Bayes\"],\n",
    "    \"Accuracy\": [lstm_test_accuracy, rf_accuracy, xgb_accuracy, accuracy],\n",
    "    \"Precision\": [lstm_precision, rf_precision, xgb_precision, precision],\n",
    "    \"Recall\": [lstm_recall, rf_recall, xgb_recall, recall],\n",
    "    \"F1-Score\": [lstm_f1, rf_f1, xgb_f1, f1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "print(\"\\nComparison of Model Results With SMOTE:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca712f2-df85-4edc-a879-f38e0065110b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
