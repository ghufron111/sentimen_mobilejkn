{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68976d98-f434-4c49-9b7b-61ab8974a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a56ada4d-abf1-4188-a8f6-a6e4844e03fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kurotsuki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function for preprocessing text\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('dataset/mobile_jkn.csv')  # Load your CSV file\n",
    "\n",
    "# Preprocess text data\n",
    "data['content'] = data['content'].apply(preprocess_text)\n",
    "\n",
    "# Remove empty content\n",
    "data = data[data['content'].str.strip() != '']  # Remove empty reviews\n",
    "\n",
    "# Features and labels\n",
    "X = data['content']\n",
    "y = data['score']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaf4f6c-5c9b-4506-9a88-6ead091de4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for text data\n",
    "max_words = 10000\n",
    "max_len = 150\n",
    "embedding_dim = 128\n",
    "\n",
    "# Tokenization and Padding\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Label Binarization\n",
    "lb = LabelBinarizer()\n",
    "y_train_onehot = lb.fit_transform(y_train)\n",
    "y_test_onehot = lb.transform(y_test)\n",
    "\n",
    "# Flattening for compatibility with models\n",
    "y_train_flat = y_train_onehot.argmax(axis=1)\n",
    "y_test_flat = y_test_onehot.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22e5dad-5ec8-4905-b534-bb9976ad978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1235/1235 [==============================] - 36s 26ms/step - loss: 0.5878 - accuracy: 0.8302 - val_loss: 0.5218 - val_accuracy: 0.8442\n",
      "Epoch 2/100\n",
      "1235/1235 [==============================] - 35s 28ms/step - loss: 0.5018 - accuracy: 0.8515 - val_loss: 0.5184 - val_accuracy: 0.8435\n",
      "Epoch 3/100\n",
      "1235/1235 [==============================] - 38s 31ms/step - loss: 0.4753 - accuracy: 0.8561 - val_loss: 0.5258 - val_accuracy: 0.8436\n",
      "Epoch 4/100\n",
      "1235/1235 [==============================] - 43s 35ms/step - loss: 0.4535 - accuracy: 0.8620 - val_loss: 0.5344 - val_accuracy: 0.8422\n",
      "Epoch 5/100\n",
      "1235/1235 [==============================] - 36s 30ms/step - loss: 0.4333 - accuracy: 0.8668 - val_loss: 0.5490 - val_accuracy: 0.8363\n",
      "Epoch 6/100\n",
      "1235/1235 [==============================] - 37s 30ms/step - loss: 0.4125 - accuracy: 0.8731 - val_loss: 0.5749 - val_accuracy: 0.8351\n",
      "Epoch 7/100\n",
      "1235/1235 [==============================] - 38s 30ms/step - loss: 0.3950 - accuracy: 0.8798 - val_loss: 0.5976 - val_accuracy: 0.8309\n",
      "Epoch 8/100\n",
      "1235/1235 [==============================] - 38s 31ms/step - loss: 0.3771 - accuracy: 0.8846 - val_loss: 0.6302 - val_accuracy: 0.8284\n",
      "Epoch 9/100\n",
      "1235/1235 [==============================] - 39s 32ms/step - loss: 0.3607 - accuracy: 0.8911 - val_loss: 0.6669 - val_accuracy: 0.8302\n",
      "Epoch 10/100\n",
      "1235/1235 [==============================] - 37s 30ms/step - loss: 0.3458 - accuracy: 0.8953 - val_loss: 0.6891 - val_accuracy: 0.8297\n",
      "Epoch 11/100\n",
      "1235/1235 [==============================] - 38s 30ms/step - loss: 0.3340 - accuracy: 0.8994 - val_loss: 0.7294 - val_accuracy: 0.8244\n",
      "618/618 [==============================] - 8s 13ms/step - loss: 0.5218 - accuracy: 0.8442\n",
      "618/618 [==============================] - 9s 13ms/step\n",
      "LSTM Test Accuracy: 0.8442183136940002\n",
      "LSTM Precision: 0.7750007130220489\n",
      "LSTM Recall: 0.8442183070068854\n",
      "LSTM F1 Score: 0.7904135813711823\n"
     ]
    }
   ],
   "source": [
    "# --- Define and Train the LSTM Model ---\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_words, embedding_dim, input_length=max_len),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(y_train_onehot.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "lstm_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model.fit(X_train_padded, y_train_onehot, epochs=100, batch_size=64,\n",
    "               validation_data=(X_test_padded, y_test_onehot), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "lstm_test_loss, lstm_test_accuracy = lstm_model.evaluate(X_test_padded, y_test_onehot)\n",
    "\n",
    "# Predict with the LSTM model\n",
    "y_pred_lstm = lstm_model.predict(X_test_padded).argmax(axis=1)\n",
    "\n",
    "# LSTM metrics\n",
    "lstm_precision = precision_score(y_test_flat, y_pred_lstm, average='weighted', zero_division=0)\n",
    "lstm_recall = recall_score(y_test_flat, y_pred_lstm, average='weighted', zero_division=0)\n",
    "lstm_f1 = f1_score(y_test_flat, y_pred_lstm, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"LSTM Test Accuracy: {lstm_test_accuracy}\")\n",
    "print(f\"LSTM Precision: {lstm_precision}\")\n",
    "print(f\"LSTM Recall: {lstm_recall}\")\n",
    "print(f\"LSTM F1 Score: {lstm_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b592b701-4ed1-4bc5-a5e7-2e81a43792ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Random Forest Model ---\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_padded, y_train_flat)\n",
    "\n",
    "# Predict with Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test_padded)\n",
    "\n",
    "# Random Forest metrics\n",
    "rf_accuracy = accuracy_score(y_test_flat, y_pred_rf)\n",
    "rf_precision = precision_score(y_test_flat, y_pred_rf, average='weighted')\n",
    "rf_recall = recall_score(y_test_flat, y_pred_rf, average='weighted')\n",
    "rf_f1 = f1_score(y_test_flat, y_pred_rf, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1530b642-799e-4da2-a875-7b3c191ec681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XGBoost Model ---\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train_padded, y_train_flat)\n",
    "\n",
    "# Predict with XGBoost\n",
    "y_pred_xgb = xgb_model.predict(X_test_padded)\n",
    "\n",
    "# XGBoost metrics\n",
    "xgb_accuracy = accuracy_score(y_test_flat, y_pred_xgb)\n",
    "xgb_precision = precision_score(y_test_flat, y_pred_xgb, average='weighted')\n",
    "xgb_recall = recall_score(y_test_flat, y_pred_xgb, average='weighted')\n",
    "xgb_f1 = f1_score(y_test_flat, y_pred_xgb, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "772b1c0f-7750-4b9d-9612-c9eecdbf7f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Performance:\n",
      "Accuracy: 0.6096597812879708\n",
      "Precision: 0.6394554663846649\n",
      "Recall: 0.6096597812879708\n",
      "F1 Score: 0.5528483909542201\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes model without SMOTE\n",
    "nb_model = MultinomialNB(alpha=0.001)  # You can adjust alpha for hyperparameter tuning\n",
    "nb_model.fit(X_train_padded, y_train_flat)\n",
    "\n",
    "# Predictions\n",
    "y_pred_flat = nb_model.predict(X_test_padded)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test_flat, y_pred_flat)\n",
    "precision = precision_score(y_test_flat, y_pred_flat, average='weighted')\n",
    "recall = recall_score(y_test_flat, y_pred_flat, average='weighted')\n",
    "f1 = f1_score(y_test_flat, y_pred_flat, average='weighted')\n",
    "\n",
    "# Display the results\n",
    "print(\"Naive Bayes Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e2e87b-e4fd-4425-bf50-dfbf93c3b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Model Results Without SMOTE:\n",
      "           Model  Accuracy  Precision    Recall  F1-Score\n",
      "0           LSTM  0.844218   0.775001  0.844218  0.790414\n",
      "1  Random Forest  0.781946   0.709381  0.781946  0.735544\n",
      "2        XGBoost  0.812880   0.728318  0.812880  0.760543\n",
      "3    Naive Bayes  0.609660   0.639455  0.609660  0.552848\n"
     ]
    }
   ],
   "source": [
    "# --- Model Results ---\n",
    "results = {\n",
    "    \"Model\": [\"LSTM\", \"Random Forest\", \"XGBoost\", \"Naive Bayes\"],\n",
    "    \"Accuracy\": [lstm_test_accuracy, rf_accuracy, xgb_accuracy, accuracy],\n",
    "    \"Precision\": [lstm_precision, rf_precision, xgb_precision, precision],\n",
    "    \"Recall\": [lstm_recall, rf_recall, xgb_recall, recall],\n",
    "    \"F1-Score\": [lstm_f1, rf_f1, xgb_f1, f1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "print(\"\\nComparison of Model Results Without SMOTE:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc65642-5138-47bf-988d-6b3930af0c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
