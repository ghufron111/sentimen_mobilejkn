{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924f9993-eae4-4206-87b4-5b6d120f4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5f61e4-c33e-4875-9d96-469ad6bcb641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "data = pd.read_csv('dataset/mobile_jkn.csv')  # Load your CSV file\n",
    "\n",
    "# Assume 'content' contains review text and 'score' contains sentiment labels\n",
    "X = data['content']  # Feature: text reviews\n",
    "y = data['score']    # Label: sentiment\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "max_words = 5000  # Maximum number of words to consider\n",
    "max_len = 200     # Maximum length of input sequences\n",
    "embedding_dim = 128  # Embedding size for each token\n",
    "\n",
    "# Tokenization of the text data\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the text data to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure uniform input shape\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "lb = LabelBinarizer()\n",
    "y_train_onehot = lb.fit_transform(y_train)\n",
    "y_test_onehot = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f62f8ba1-9592-4d0d-a091-3e1c26b3a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Penyeimbangan Data Menggunakan SMOTE -------------------- #\n",
    "\n",
    "# Resample training data using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_padded_resampled, y_train_onehot_resampled = smote.fit_resample(X_train_padded, y_train_onehot)\n",
    "\n",
    "# Flatten y_train_onehot_resampled and y_test_onehot for SVM, Naive Bayes, and KNN compatibility\n",
    "y_train_flat = y_train_onehot_resampled.argmax(axis=1)\n",
    "y_test_flat = y_test_onehot.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "617cdd5b-562c-463f-a3be-be8dd98ad2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1932/1932 [==============================] - 62s 31ms/step - loss: 1.2435 - accuracy: 0.4368 - val_loss: 0.7674 - val_accuracy: 0.7746 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1932/1932 [==============================] - 59s 31ms/step - loss: 1.1630 - accuracy: 0.4768 - val_loss: 0.7607 - val_accuracy: 0.7928 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1932/1932 [==============================] - 59s 31ms/step - loss: 1.1297 - accuracy: 0.4900 - val_loss: 0.7118 - val_accuracy: 0.8046 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1932/1932 [==============================] - 59s 31ms/step - loss: 1.1059 - accuracy: 0.4990 - val_loss: 0.6926 - val_accuracy: 0.8209 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1932/1932 [==============================] - 60s 31ms/step - loss: 1.0878 - accuracy: 0.5079 - val_loss: 0.7122 - val_accuracy: 0.8128 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1932/1932 [==============================] - 60s 31ms/step - loss: 1.0737 - accuracy: 0.5127 - val_loss: 0.7027 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1932/1932 [==============================] - 60s 31ms/step - loss: 1.0422 - accuracy: 0.5272 - val_loss: 0.7236 - val_accuracy: 0.8133 - lr: 2.0000e-04\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.6926 - accuracy: 0.8209\n",
      "625/625 [==============================] - 5s 7ms/step\n",
      "LSTM Test Accuracy: 0.820900022983551\n",
      "LSTM Precision: 0.7808043063174731\n",
      "LSTM Recall: 0.8209\n",
      "LSTM F1-Score: 0.7949926657977024\n"
     ]
    }
   ],
   "source": [
    "# -------------------- LSTM Model -------------------- #\n",
    "\n",
    "# Build the LSTM model using TensorFlow\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_words, embedding_dim, input_length=max_len),\n",
    "    tf.keras.layers.SpatialDropout1D(0.2),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(y_train_onehot.shape[1], activation='softmax')  # Adjust output classes dynamically\n",
    "])\n",
    "\n",
    "# Compile the LSTM model\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_lstm_model.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
    "\n",
    "# Train the LSTM model with callbacks\n",
    "lstm_model.fit(\n",
    "    X_train_padded_resampled, \n",
    "    y_train_onehot_resampled, \n",
    "    epochs=10, \n",
    "    batch_size=128, \n",
    "    validation_data=(X_test_padded, y_test_onehot),\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the LSTM model on the test set\n",
    "lstm_test_loss, lstm_test_accuracy = lstm_model.evaluate(X_test_padded, y_test_onehot)\n",
    "\n",
    "# Predict with LSTM\n",
    "y_pred_lstm = lstm_model.predict(X_test_padded)\n",
    "y_pred_lstm_flat = y_pred_lstm.argmax(axis=1)\n",
    "\n",
    "# LSTM Precision, Recall, F1-Score\n",
    "lstm_precision = precision_score(y_test_flat, y_pred_lstm_flat, average='weighted')\n",
    "lstm_recall = recall_score(y_test_flat, y_pred_lstm_flat, average='weighted')\n",
    "lstm_f1 = f1_score(y_test_flat, y_pred_lstm_flat, average='weighted')\n",
    "\n",
    "print(f\"LSTM Test Accuracy: {lstm_test_accuracy}\")\n",
    "print(f\"LSTM Precision: {lstm_precision}\")\n",
    "print(f\"LSTM Recall: {lstm_recall}\")\n",
    "print(f\"LSTM F1-Score: {lstm_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d6ac81-a13e-424d-9603-056b5fc578e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Processed 4.05% of data\n",
      "Processed 8.09% of data\n",
      "Processed 12.14% of data\n",
      "Processed 16.18% of data\n",
      "Processed 20.23% of data\n",
      "Processed 24.27% of data\n",
      "Processed 28.32% of data\n",
      "Processed 32.36% of data\n",
      "Processed 36.41% of data\n",
      "Processed 40.45% of data\n",
      "Processed 44.50% of data\n",
      "Processed 48.54% of data\n",
      "Processed 52.59% of data\n",
      "Processed 56.63% of data\n",
      "Processed 60.68% of data\n",
      "Processed 64.72% of data\n",
      "Processed 68.77% of data\n",
      "Processed 72.81% of data\n",
      "Processed 76.86% of data\n",
      "Processed 80.90% of data\n",
      "Processed 84.95% of data\n",
      "Processed 88.99% of data\n",
      "Processed 93.04% of data\n",
      "Processed 97.08% of data\n",
      "Processed 100.00% of data\n",
      "Epoch 2/5\n",
      "Processed 4.05% of data\n",
      "Processed 8.09% of data\n",
      "Processed 12.14% of data\n",
      "Processed 16.18% of data\n",
      "Processed 20.23% of data\n",
      "Processed 24.27% of data\n",
      "Processed 28.32% of data\n",
      "Processed 32.36% of data\n",
      "Processed 36.41% of data\n",
      "Processed 40.45% of data\n",
      "Processed 44.50% of data\n",
      "Processed 48.54% of data\n",
      "Processed 52.59% of data\n",
      "Processed 56.63% of data\n",
      "Processed 60.68% of data\n",
      "Processed 64.72% of data\n",
      "Processed 68.77% of data\n",
      "Processed 72.81% of data\n",
      "Processed 76.86% of data\n",
      "Processed 80.90% of data\n",
      "Processed 84.95% of data\n",
      "Processed 88.99% of data\n",
      "Processed 93.04% of data\n",
      "Processed 97.08% of data\n",
      "Processed 100.00% of data\n",
      "Epoch 3/5\n",
      "Processed 4.05% of data\n",
      "Processed 8.09% of data\n",
      "Processed 12.14% of data\n",
      "Processed 16.18% of data\n",
      "Processed 20.23% of data\n",
      "Processed 24.27% of data\n",
      "Processed 28.32% of data\n",
      "Processed 32.36% of data\n",
      "Processed 36.41% of data\n",
      "Processed 40.45% of data\n",
      "Processed 44.50% of data\n",
      "Processed 48.54% of data\n",
      "Processed 52.59% of data\n",
      "Processed 56.63% of data\n",
      "Processed 60.68% of data\n",
      "Processed 64.72% of data\n",
      "Processed 68.77% of data\n",
      "Processed 72.81% of data\n",
      "Processed 76.86% of data\n",
      "Processed 80.90% of data\n",
      "Processed 84.95% of data\n",
      "Processed 88.99% of data\n",
      "Processed 93.04% of data\n",
      "Processed 97.08% of data\n",
      "Processed 100.00% of data\n",
      "Epoch 4/5\n",
      "Processed 4.05% of data\n",
      "Processed 8.09% of data\n",
      "Processed 12.14% of data\n",
      "Processed 16.18% of data\n",
      "Processed 20.23% of data\n",
      "Processed 24.27% of data\n",
      "Processed 28.32% of data\n",
      "Processed 32.36% of data\n",
      "Processed 36.41% of data\n",
      "Processed 40.45% of data\n",
      "Processed 44.50% of data\n",
      "Processed 48.54% of data\n",
      "Processed 52.59% of data\n",
      "Processed 56.63% of data\n",
      "Processed 60.68% of data\n",
      "Processed 64.72% of data\n",
      "Processed 68.77% of data\n",
      "Processed 72.81% of data\n",
      "Processed 76.86% of data\n",
      "Processed 80.90% of data\n",
      "Processed 84.95% of data\n",
      "Processed 88.99% of data\n",
      "Processed 93.04% of data\n",
      "Processed 97.08% of data\n",
      "Processed 100.00% of data\n",
      "Epoch 5/5\n",
      "Processed 4.05% of data\n",
      "Processed 8.09% of data\n",
      "Processed 12.14% of data\n",
      "Processed 16.18% of data\n",
      "Processed 20.23% of data\n",
      "Processed 24.27% of data\n",
      "Processed 28.32% of data\n",
      "Processed 32.36% of data\n",
      "Processed 36.41% of data\n",
      "Processed 40.45% of data\n",
      "Processed 44.50% of data\n",
      "Processed 48.54% of data\n",
      "Processed 52.59% of data\n",
      "Processed 56.63% of data\n",
      "Processed 60.68% of data\n",
      "Processed 64.72% of data\n",
      "Processed 68.77% of data\n",
      "Processed 72.81% of data\n",
      "Processed 76.86% of data\n",
      "Processed 80.90% of data\n",
      "Processed 84.95% of data\n",
      "Processed 88.99% of data\n",
      "Processed 93.04% of data\n",
      "Processed 97.08% of data\n",
      "Processed 100.00% of data\n",
      "SVM per Batch Test Accuracy: 0.13455\n",
      "SVM per Batch Precision: 0.4209379898658397\n",
      "SVM per Batch Recall: 0.13455\n",
      "SVM per Batch F1-Score: 0.18164644267313018\n",
      "\n",
      "Total Hasil Evaluasi SVM:\n",
      "Total Accuracy: 0.13455\n",
      "Total Precision: 0.4209379898658397\n",
      "Total Recall: 0.13455\n",
      "Total F1-Score: 0.18164644267313018\n"
     ]
    }
   ],
   "source": [
    "# -------------------- SVM per Batch with SGDClassifier -------------------- #\n",
    "\n",
    "# Standarisasi fitur input (karena SVM sensitif terhadap skala fitur)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_padded_resampled)\n",
    "X_test_scaled = scaler.transform(X_test_padded)\n",
    "\n",
    "# Inisialisasi SGDClassifier untuk linear SVM\n",
    "svm_batch_model = SGDClassifier(loss='hinge', random_state=42)\n",
    "\n",
    "# Konfigurasi batch\n",
    "batch_size = 10000  # Ukuran batch diatur ke 10.000\n",
    "n_batches = len(X_train_scaled) // batch_size + 1  # Menentukan jumlah batch\n",
    "\n",
    "# Variabel untuk menyimpan total\n",
    "total_accuracy = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "\n",
    "# Train SVM model per batch\n",
    "for epoch in range(5):  # Tentukan jumlah epoch\n",
    "    X_train_scaled, y_train_flat = shuffle(X_train_scaled, y_train_flat, random_state=42)  # Shuffle data di setiap epoch\n",
    "    print(f\"Epoch {epoch+1}/{5}\")\n",
    "    \n",
    "    for i in range(0, len(X_train_scaled), batch_size):\n",
    "        # Mendapatkan batch saat ini\n",
    "        X_batch = X_train_scaled[i:i+batch_size]\n",
    "        y_batch = y_train_flat[i:i+batch_size]\n",
    "        \n",
    "        # Partial fit menggunakan batch\n",
    "        svm_batch_model.partial_fit(X_batch, y_batch, classes=np.unique(y_train_flat))\n",
    "        \n",
    "        # Menampilkan progress setiap batch\n",
    "        progress = (i + len(X_batch)) / len(X_train_scaled) * 100\n",
    "        print(f\"Processed {progress:.2f}% of data\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_svm_batch = svm_batch_model.predict(X_test_scaled)\n",
    "\n",
    "# SVM Accuracy\n",
    "svm_batch_accuracy = accuracy_score(y_test_flat, y_pred_svm_batch)\n",
    "print(f\"SVM per Batch Test Accuracy: {svm_batch_accuracy}\")\n",
    "\n",
    "# SVM Precision, Recall, F1-Score\n",
    "svm_batch_precision = precision_score(y_test_flat, y_pred_svm_batch, average='weighted')\n",
    "svm_batch_recall = recall_score(y_test_flat, y_pred_svm_batch, average='weighted')\n",
    "svm_batch_f1 = f1_score(y_test_flat, y_pred_svm_batch, average='weighted')\n",
    "\n",
    "# Menambahkan hasil ke total\n",
    "total_accuracy += svm_batch_accuracy\n",
    "total_precision += svm_batch_precision\n",
    "total_recall += svm_batch_recall\n",
    "total_f1 += svm_batch_f1\n",
    "\n",
    "print(f\"SVM per Batch Precision: {svm_batch_precision}\")\n",
    "print(f\"SVM per Batch Recall: {svm_batch_recall}\")\n",
    "print(f\"SVM per Batch F1-Score: {svm_batch_f1}\")\n",
    "\n",
    "# Tampilkan hasil total SVM\n",
    "print(\"\\nTotal Hasil Evaluasi SVM:\")\n",
    "print(f\"Total Accuracy: {total_accuracy}\")\n",
    "print(f\"Total Precision: {total_precision}\")\n",
    "print(f\"Total Recall: {total_recall}\")\n",
    "print(f\"Total F1-Score: {total_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a812a777-0ba3-4e4b-b87d-cc33d35ef1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Test Accuracy: 0.22685\n",
      "Naive Bayes Precision: 0.6207400784221465\n",
      "Naive Bayes Recall: 0.22685\n",
      "Naive Bayes F1-Score: 0.2863439658345516\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Naive Bayes Model -------------------- #\n",
    "\n",
    "# Train Naive Bayes model with resampled training data\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_padded_resampled, y_train_flat)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_nb = nb_model.predict(X_test_padded)\n",
    "\n",
    "# Naive Bayes Accuracy\n",
    "nb_accuracy = accuracy_score(y_test_flat, y_pred_nb)\n",
    "print(f\"Naive Bayes Test Accuracy: {nb_accuracy}\")\n",
    "\n",
    "# Naive Bayes Precision, Recall, F1-Score\n",
    "nb_precision = precision_score(y_test_flat, y_pred_nb, average='weighted')\n",
    "nb_recall = recall_score(y_test_flat, y_pred_nb, average='weighted')\n",
    "nb_f1 = f1_score(y_test_flat, y_pred_nb, average='weighted')\n",
    "\n",
    "print(f\"Naive Bayes Precision: {nb_precision}\")\n",
    "print(f\"Naive Bayes Recall: {nb_recall}\")\n",
    "print(f\"Naive Bayes F1-Score: {nb_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b87f02c1-5614-4985-a57e-e0f42bfd97fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test Accuracy: 0.1537\n",
      "KNN Precision: 0.3906920264990941\n",
      "KNN Recall: 0.1537\n",
      "KNN F1-Score: 0.1675206580793207\n"
     ]
    }
   ],
   "source": [
    "# -------------------- KNN Model -------------------- #\n",
    "\n",
    "# Train KNN model with resampled training data\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_padded_resampled, y_train_flat)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_knn = knn_model.predict(X_test_padded)\n",
    "\n",
    "# KNN Accuracy\n",
    "knn_accuracy = accuracy_score(y_test_flat, y_pred_knn)\n",
    "print(f\"KNN Test Accuracy: {knn_accuracy}\")\n",
    "\n",
    "# KNN Precision, Recall, F1-Score\n",
    "knn_precision = precision_score(y_test_flat, y_pred_knn, average='weighted')\n",
    "knn_recall = recall_score(y_test_flat, y_pred_knn, average='weighted')\n",
    "knn_f1 = f1_score(y_test_flat, y_pred_knn, average='weighted')\n",
    "\n",
    "print(f\"KNN Precision: {knn_precision}\")\n",
    "print(f\"KNN Recall: {knn_recall}\")\n",
    "print(f\"KNN F1-Score: {knn_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac71bc18-fe53-4132-9524-e5b35d36cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Comparison of Results -------------------- #\n",
    "\n",
    "print(\"\\nComparison of Model Results:\")\n",
    "print(f\"LSTM Test Accuracy: {lstm_test_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}, F1-Score: {lstm_f1}\")\n",
    "print(f\"SVM Test Accuracy: {svm_accuracy}, Precision: {svm_precision}, Recall: {svm_recall}, F1-Score: {svm_f1}\")\n",
    "print(f\"Naive Bayes Test Accuracy: {nb_accuracy}, Precision: {nb_precision}, Recall: {nb_recall}, F1-Score: {nb_f1}\")\n",
    "print(f\"KNN Test Accuracy: {knn_accuracy}, Precision: {knn_precision}, Recall: {knn_recall}, F1-Score: {knn_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
